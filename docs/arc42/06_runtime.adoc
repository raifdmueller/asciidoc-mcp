== 6. Runtime View

This chapter illustrates how the system's components collaborate at runtime to fulfill key use cases.

=== 6.1 Scenario: Reading a Document Section

This is the most common read operation. A client requests the content of a specific section using its hierarchical path.

[plantuml, usecase-read-sequence, svg]
----
@startuml
title Sequence Diagram: Reading a Section

participant "MCP Client" as Client
participant "MCP Server" as Server
participant "Structure Index" as Idx
participant "File System" as FS

Client -> Server: GET /section?path=chapter-1.section-2
activate Server

Server -> Idx: find_section("chapter-1.section-2")
activate Idx
Idx --> Server: SectionLocation(file: "chapter1.adoc", start: 10, end: 50)
deactivate Idx

Server -> FS: read_lines("chapter1.adoc", 10, 50)
activate FS
FS --> Server: File Content
deactivate FS

Server --> Client: 200 OK (Content)
deactivate Server
@enduml
----

=== 6.2 Scenario: Updating a Document Section

This scenario shows the critical write operation. The process must be atomic to ensure data integrity, as required by quality goal REL-1. This is achieved by writing to a temporary file first.

[plantuml, usecase-update-sequence, svg]
----
@startuml
title Sequence Diagram: Updating a Section (Atomic Write)

participant "MCP Client" as Client
participant "MCP Server" as Server
participant "File System Handler" as FSH
participant "File System" as FS

Client -> Server: POST /update_section\n(path: "chapter-1.section-2", content: "New text...")
activate Server

Server -> FSH: update_section("chapter-1.section-2", "New text...")
activate FSH

FSH -> FS: copy("chapter1.adoc", "chapter1.adoc.bak")
FSH -> FS: write_to_temp("chapter1.adoc.tmp", updated_content)

alt successful write
    FSH -> FS: move("chapter1.adoc.tmp", "chapter1.adoc")
    FSH -> FS: delete("chapter1.adoc.bak")
    FSH --> Server: Success
else write failed
    FSH -> FS: delete("chapter1.adoc.tmp")
    FSH -> FS: restore("chapter1.adoc.bak", "chapter1.adoc")
    FSH --> Server: Error
end

deactivate FSH

Server --> Client: 200 OK or 500 Error
deactivate Server
@enduml
----

=== 6.3 Scenario: Server Initialization

When the server starts, it needs to parse the entire documentation project to build an in-memory index of the structure. This enables fast lookups for subsequent requests.

[plantuml, usecase-init-sequence, svg]
----
@startuml
title Sequence Diagram: Server Initialization

participant "Operator" as Operator
participant "MCP Server" as Server
participant "Document Parser" as Parser
participant "Structure Index" as Idx
participant "File System" as FS

Operator -> Server: start()
activate Server

Server -> FS: list_files("**/*.adoc, **/*.md")
activate FS
FS --> Server: file_list
deactivate FS

loop for each file in file_list
    Server -> Parser: parse(file)
    activate Parser
    Parser -> FS: read_file(file)
    note right of Parser: Resolves includes
    Parser --> Server: Document AST
    deactivate Parser

    Server -> Idx: build_index(AST)
    activate Idx
    Idx --> Server: done
    deactivate Idx
end

Server --> Operator: Server Ready
deactivate Server
@enduml
----

> **Note:** The scenarios above reflect the initial design. The following sections document additional runtime flows from the actual implementation (Oct 2025).

=== 6.4 Scenario: File Watching and Auto-Refresh (Actual Implementation)

The implemented system includes automatic file watching to keep the in-memory index synchronized with external file changes. This enables editors to modify files outside the MCP server while keeping the index current.

**Mental Model:** *"Watch, detect, re-parse, refresh"*

[plantuml, file-watching-sequence, svg]
----
@startuml
title Sequence Diagram: File Watching and Auto-Refresh

participant "External Editor" as Editor
participant "File System" as FS
participant "FileWatcher" as Watcher
participant "MCPDocumentationServer" as Server
participant "DocumentParser" as Parser
participant "Structure Index" as Idx

== Initial Setup ==
Server -> Watcher: start(project_root, callback=_on_files_changed)
activate Watcher
Watcher -> FS: register_observer(project_root)
note right of Watcher: Uses watchdog library\ninotify/FSEvents

== External File Modification ==
Editor -> FS: modify("docs/chapter1.adoc")
activate FS
FS --> Editor: saved
deactivate FS

FS -> Watcher: file_modified_event("docs/chapter1.adoc")
activate Watcher
Watcher -> Server: _on_files_changed({"chapter1.adoc"})
deactivate Watcher

activate Server
note right of Server: Debounce multiple events\n(wait 500ms for batch)

Server -> Server: _discover_root_files()
Server -> Server: _parse_project()

loop for changed files
    Server -> Parser: parse("chapter1.adoc")
    activate Parser
    Parser --> Server: updated AST
    deactivate Parser

    Server -> Idx: rebuild_sections()
    activate Idx
    note right of Idx: Updates self.sections dict\nin-memory
    Idx --> Server: done
    deactivate Idx
end

Server -> Server: log("Index refreshed")
deactivate Server

@enduml
----

**Key Implementation Details:**

1. **Watchdog Library** - Uses platform-specific file system events (inotify on Linux, FSEvents on macOS)
2. **Debouncing** - Multiple rapid changes batched to avoid re-parsing storm
3. **Selective Re-parse** - Only changed files re-parsed (optimization)
4. **In-Memory Update** - `self.sections` dictionary updated atomically

**Performance:**
- Event detection: <50ms
- Re-parse single file: <100ms
- Index update: <500ms total

**Mental Model Insight:**
The file system is the "source of truth" (ADR-001), but the in-memory index is the "performance cache." File watching bridges these two worlds, keeping them synchronized without manual refresh.

=== 6.5 Scenario: Web Server Startup and Auto-Launch (Actual Implementation)

The web server runs in a background thread and automatically finds a free port, avoiding conflicts. It also auto-launches the browser for immediate user access.

**Mental Model:** *"Find port, start thread, open browser"*

[plantuml, webserver-startup-sequence, svg]
----
@startuml
title Sequence Diagram: Web Server Startup and Auto-Launch

participant "Main Process" as Main
participant "WebserverManager" as WSM
participant "MCPDocumentationServer" as Server
participant "Web Server Thread" as Thread
participant "FastAPI Server" as FastAPI
participant "Browser" as Browser

== Server Initialization ==
Main -> Server: __init__(project_root, enable_webserver=True)
activate Server

Server -> WSM: __init__(self)
activate WSM
note right of WSM: self.webserver_url = None\nself.webserver_started = False

Server -> Server: _parse_project()
note right of Server: Index ready

Server -> WSM: start_webserver_thread()

== Find Free Port ==
WSM -> WSM: find_free_port(start_port=8080)
activate WSM
loop port in range(8080, 8099)
    WSM -> WSM: try_bind(port)
    alt port available
        note right of WSM: Port 8080 in use
    else port free
        note right of WSM: Found port 8081
        WSM -> WSM: return 8081
    end
end
deactivate WSM

== Start Background Thread ==
WSM -> Thread: Thread(target=_run_webserver, daemon=True)
activate Thread
note right of Thread: Daemon thread exits\nwhen main process exits

WSM -> Thread: start()
Thread -> FastAPI: uvicorn.run(app, port=8081)
activate FastAPI
note right of FastAPI: Runs in background\nnon-blocking

== Auto-Launch Browser ==
WSM -> WSM: sleep(1.0)  # Wait for server ready
WSM -> Browser: webbrowser.open("http://localhost:8081")
activate Browser
note right of Browser: Opens default browser\nto web interface
Browser --> WSM: (browser window opened)
deactivate Browser

WSM -> WSM: webserver_url = "http://localhost:8081"
WSM -> WSM: webserver_started = True
WSM --> Server: Web server started
deactivate WSM
deactivate Thread
deactivate FastAPI

Server --> Main: Server Ready (MCP + Web)
deactivate Server

@enduml
----

**Key Implementation Details:**

1. **Port Management** (see ADR-006)
   - Tries ports 8080-8099 sequentially
   - Binds to first available port
   - Handles port conflicts gracefully

2. **Background Threading**
   - Daemon thread (exits with main process)
   - Non-blocking startup
   - MCP server continues serving requests

3. **Auto-Browser-Launch**
   - 1-second delay for server readiness
   - Uses `webbrowser` module (cross-platform)
   - Fails gracefully if no browser available

4. **Status Tracking**
   - `webserver_url` and `webserver_started` flags
   - `get_webserver_status()` API for monitoring

**Performance:**
- Port finding: <100ms (typical)
- Thread startup: <500ms
- Browser launch: <1s
- Total: <2s from server start to web UI available

**Mental Model Insight:**
The web server is a "bonus interface" - the MCP server works fine without it. Threading keeps them independent: MCP protocol on main thread, HTTP on background thread. If web server fails, MCP continues working.

=== 6.6 Scenario: MCP Protocol Request Handling (FastMCP SDK)

This scenario shows the actual flow using FastMCP SDK (ADR-009, migrated Oct 2025).

[plantuml, mcp-protocol-flow, svg]
----
@startuml
title Sequence Diagram: MCP Protocol Request Handling (FastMCP)

participant "MCP Client" as Client
participant "FastMCP SDK" as FastMCP
participant "@mcp.tool()" as Tool
participant "document_api.py" as DocAPI
participant "Structure Index" as Idx

== MCP Request ==
Client -> FastMCP: JSON-RPC request via stdin\n{"method": "tools/call", "params": {"name": "get_structure"}}
activate FastMCP

FastMCP -> FastMCP: parse JSON-RPC
note right of FastMCP: Automatic parsing\nby SDK

FastMCP -> FastMCP: validate schema
note right of FastMCP: Schema from\ntype hints

== Tool Dispatch ==
FastMCP -> Tool: get_structure(start_level=1, parent_id=None)
activate Tool
note right of Tool: Decorated function:\n@mcp.tool()\ndef get_structure(...)

Tool -> Tool: access _server (global)
note right of Tool: Global server instance\nset in main()

== Tool Execution ==
Tool -> DocAPI: _server.doc_api.get_structure(start_level, parent_id)
activate DocAPI

DocAPI -> Idx: access self.server.sections
activate Idx
note right of Idx: Shared state via\nDI pattern

Idx --> DocAPI: sections dict
deactivate Idx

DocAPI -> DocAPI: _build_hierarchy(sections)
note right of DocAPI: Recursive tree building

DocAPI --> Tool: {"chapter-1": {...}, "chapter-2": {...}}
deactivate DocAPI

Tool --> FastMCP: return dict
deactivate Tool

== Response Formatting ==
FastMCP -> FastMCP: serialize_response(result)
note right of FastMCP: Automatic JSON-RPC\nwrapping by SDK

FastMCP --> Client: JSON-RPC response via stdout
deactivate FastMCP

@enduml
----

**Key Architecture Points:**

1. **FastMCP SDK Integration** (ADR-009)
   - Replaces manual `protocol_handler.py` (282 lines deleted)
   - `@mcp.tool()` decorators for tool registration
   - Automatic schema generation from Python type hints
   - Built-in JSON-RPC 2.0 compliance

2. **Decorator-Based Tool Registration**
   - 10 tools registered with `@mcp.tool()` decorators
   - Type hints: `def get_section(path: str) -> dict` â†’ auto-generates schema
   - Docstrings become tool descriptions
   - Global `_server` instance for state access

3. **Dependency Injection Pattern Maintained**
   - `DocAPI` still receives `self.server` instance
   - Access to shared state (`sections`, `parser`, etc.)
   - No circular dependencies
   - Business logic unchanged

4. **SDK Advantages**
   - Protocol compliance guaranteed (official Anthropic SDK)
   - Automatic protocol updates via `pip install --upgrade mcp`
   - Less boilerplate: -638 lines total code reduction
   - Better testability (SDK handles protocol edge cases)

**Performance:**
- SDK parsing/routing: <2ms (slightly slower than manual, but negligible)
- Tool execution: <100ms (typical, unchanged)
- SDK response formatting: <1ms
- **Total: <100ms end-to-end** (no measurable difference)

=== 6.7 Runtime Performance Characteristics

**Startup Performance:**
- File discovery: ~50ms (for 50 files)
- Parsing: ~1-2s (for 600 pages)
- Index building: ~100ms
- Web server startup: ~500ms
- **Total: <3s cold start**

**Request Performance:**
- `get_structure()`: 10-50ms (in-memory)
- `get_section()`: 5-20ms (index lookup + file read)
- `search_content()`: 50-200ms (linear scan)
- `update_section()`: 100-500ms (atomic write + re-parse)

**Memory Footprint:**
- Base server: ~20MB
- Index for 1000 sections: ~1MB
- Total for 600-page project: ~50MB

**CPU Usage:**
- Idle: <1%
- File watching: <1%
- During request: 5-20% (brief spike)

These measurements validate the quality goals defined in Chapter 10.